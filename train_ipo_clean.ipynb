{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6b471f5",
   "metadata": {},
   "source": [
    "# GPT-2 IPO Training\n",
    "\n",
    "Minimal implementation of Implicit Preference Optimization (IPO) training for GPT-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d240952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.utils as utils\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "class PreferenceDataset(Dataset):\n",
    "    def __init__(self, json_path):\n",
    "        with open(json_path, 'r') as f:\n",
    "            raw_data = json.load(f)\n",
    "\n",
    "        self.data = []\n",
    "        for question, entry in raw_data.items():\n",
    "            for hop, hop_data in entry[\"hops\"].items():\n",
    "                queries = hop_data[\"queries\"]\n",
    "                preferences = hop_data[\"preference_pairs\"]\n",
    "                for i, j in preferences:\n",
    "                    self.data.append({\n",
    "                        \"question\": question,\n",
    "                        \"preferred\": queries[i],\n",
    "                        \"dispreferred\": queries[j]\n",
    "                    })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1818b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "model.train()\n",
    "print(f\"Model {model_name} loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc6defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logp(prompt, completion):\n",
    "    \"\"\"Compute log probability of completion given prompt\"\"\"\n",
    "    full_input = prompt + completion\n",
    "    encoded = tokenizer(full_input, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    input_ids = encoded.input_ids.to(device)\n",
    "    attention_mask = encoded.attention_mask.to(device)\n",
    "    \n",
    "    prompt_encoded = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    prompt_len = prompt_encoded.input_ids.shape[-1]\n",
    "    \n",
    "    labels = input_ids.clone()\n",
    "    labels[:, :prompt_len] = -100\n",
    "    \n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    return -outputs.loss\n",
    "\n",
    "def ipo_loss(logp_win, logp_lose, tau=0.05):\n",
    "    \"\"\"Compute IPO loss\"\"\"\n",
    "    diff = logp_win - logp_lose - 0.5 / tau\n",
    "    return (diff ** 2).mean()\n",
    "\n",
    "# Training setup\n",
    "dataset_path = 'preference_dataset_hotpotqa_final.json'\n",
    "dataset = PreferenceDataset(dataset_path)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
    "tau = 0.05\n",
    "num_epochs = 3\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Starting IPO training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        questions = batch[\"question\"]\n",
    "        preferred = batch[\"preferred\"]\n",
    "        dispreferred = batch[\"dispreferred\"]\n",
    "        \n",
    "        logp_w_list = []\n",
    "        logp_l_list = []\n",
    "        \n",
    "        for q, w, l in zip(questions, preferred, dispreferred):\n",
    "            prompt = f\"Generate a search query for: {q}\\nQuery: \"\n",
    "            \n",
    "            logp_w = compute_logp(prompt, w.strip())\n",
    "            logp_l = compute_logp(prompt, l.strip())\n",
    "            \n",
    "            logp_w_list.append(logp_w)\n",
    "            logp_l_list.append(logp_l)\n",
    "        \n",
    "        logp_w_batch = torch.stack(logp_w_list)\n",
    "        logp_l_batch = torch.stack(logp_l_list)\n",
    "        \n",
    "        loss = ipo_loss(logp_w_batch, logp_l_batch, tau)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        avg_loss = total_loss / (batch_idx + 1)\n",
    "        pbar.set_postfix({\"loss\": f\"{avg_loss:.4f}\"})\n",
    "    \n",
    "    print(f\"[Epoch {epoch + 1}] Average Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6b471f5",
   "metadata": {},
   "source": [
    "# FLAN T 5 IPO Training\n",
    "\n",
    "Minimal implementation of Implicit Preference Optimization (IPO) training for FLAN T 5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d240952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.utils as utils\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "class PreferenceDataset(Dataset):\n",
    "    def __init__(self, json_path):\n",
    "        with open(json_path, 'r') as f:\n",
    "            raw_data = json.load(f)\n",
    "\n",
    "        self.data = []\n",
    "        for question, entry in raw_data.items():\n",
    "            for hop, hop_data in entry[\"hops\"].items():\n",
    "                queries = hop_data[\"queries\"]\n",
    "                preferences = hop_data[\"preference_pairs\"]\n",
    "                for i, j in preferences:\n",
    "                    self.data.append({\n",
    "                        \"question\": question,\n",
    "                        \"preferred\": queries[i],\n",
    "                        \"dispreferred\": queries[j]\n",
    "                    })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1818b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the model loading cell with:\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"google/flan-t5-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "model.train()\n",
    "print(f\"Model {model_name} loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc6defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logp(prompt, completion):\n",
    "    \"\"\"Compute log probability of completion given prompt for seq2seq model\"\"\"\n",
    "    # For T5, input is the prompt, target is the completion\n",
    "    input_encoded = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    target_encoded = tokenizer(completion, return_tensors=\"pt\", truncation=True, max_length=64)\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    input_ids = input_encoded.input_ids.to(device)\n",
    "    input_attention_mask = input_encoded.attention_mask.to(device)\n",
    "    labels = target_encoded.input_ids.to(device)\n",
    "    \n",
    "    # Replace pad tokens in labels with -100\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=input_attention_mask,\n",
    "        labels=labels\n",
    "    )\n",
    "    return -outputs.loss\n",
    "\n",
    "def ipo_loss(logp_win, logp_lose, tau=0.05):\n",
    "    \"\"\"Compute IPO loss\"\"\"\n",
    "    diff = logp_win - logp_lose - 0.5 / tau\n",
    "    return (diff ** 2).mean()\n",
    "\n",
    "# Training setup\n",
    "dataset_path = 'preference_dataset_hotpotqa_final.json'\n",
    "dataset = PreferenceDataset(dataset_path)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
    "tau = 0.05\n",
    "num_epochs = 3\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Starting IPO training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        questions = batch[\"question\"]\n",
    "        preferred = batch[\"preferred\"]\n",
    "        dispreferred = batch[\"dispreferred\"]\n",
    "        \n",
    "        logp_w_list = []\n",
    "        logp_l_list = []\n",
    "        \n",
    "        for q, w, l in zip(questions, preferred, dispreferred):\n",
    "            prompt = f\"Generate a search query for: {q}\\nQuery: \"\n",
    "            \n",
    "            logp_w = compute_logp(prompt, w.strip())\n",
    "            logp_l = compute_logp(prompt, l.strip())\n",
    "            \n",
    "            logp_w_list.append(logp_w)\n",
    "            logp_l_list.append(logp_l)\n",
    "        \n",
    "        logp_w_batch = torch.stack(logp_w_list)\n",
    "        logp_l_batch = torch.stack(logp_l_list)\n",
    "        \n",
    "        loss = ipo_loss(logp_w_batch, logp_l_batch, tau)\n",
    "\n",
    "        # if a loss is NaN, skip the step\n",
    "        if torch.isnan(loss):\n",
    "            print(f\"Skipping batch {batch_idx} due to NaN loss.\")\n",
    "            continue\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        avg_loss = total_loss / (batch_idx + 1)\n",
    "        pbar.set_postfix({\"loss\": f\"{avg_loss:.4f}\"})\n",
    "    \n",
    "    print(f\"[Epoch {epoch + 1}] Average Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query(question, max_length=30, temperature=0.8, top_p=0.9):\n",
    "    \"\"\"Generate a search query for the given question using the trained T5 model\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # T5 works better with clear instruction format\n",
    "    prompt = f\"Generate a search query for this question: {question}\"\n",
    "    encoded = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    input_ids = encoded.input_ids.to(device)\n",
    "    attention_mask = encoded.attention_mask.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=max_length,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "            early_stopping=False,\n",
    "            repetition_penalty=1.2,\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "    \n",
    "    # For seq2seq models, decode the entire output (no need to slice)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Clean up the generated text\n",
    "    generated_text = generated_text.strip()\n",
    "    \n",
    "    # Remove question marks and periods\n",
    "    generated_text = generated_text.replace('?', '').replace('.', '')\n",
    "    \n",
    "    \n",
    "    return generated_text if generated_text else \"search query\"\n",
    "\n",
    "# Test with example questions\n",
    "test_questions = [\n",
    "    \"Who was the first person to climb Mount Everest?\",\n",
    "    \"What is the capital of the country where the Eiffel Tower is located?\",\n",
    "    \"Which movie won the Academy Award for Best Picture in 2020?\",\n",
    "    \"What is the largest planet in our solar system?\",\n",
    "    \"Who wrote the novel '1984'?\"\n",
    "]\n",
    "\n",
    "print(\"Testing the trained model on example questions:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{i}. Question: {question}\")\n",
    "    \n",
    "    # Generate multiple queries with different parameters\n",
    "    configs = [\n",
    "        {\"temperature\": 0.5, \"top_p\": 0.8},\n",
    "        {\"temperature\": 0.8, \"top_p\": 0.9},\n",
    "        {\"temperature\": 1.0, \"top_p\": 0.95}\n",
    "    ]\n",
    "    \n",
    "    for j, config in enumerate(configs):\n",
    "        query = generate_query(question, **config)\n",
    "        print(f\"   Query {j+1}: {query}\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\nTesting completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

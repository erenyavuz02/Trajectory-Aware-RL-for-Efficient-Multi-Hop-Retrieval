# Trajectory-Aware-RL-for-Efficient-Multi-Hop-Retrieval

## Project Overview

This project implements a trajectory-aware reinforcement learning approach for efficient multi-hop question answering and retrieval using the HotpotQA dataset. The system combines preference learning, adaptive hop classification, and query generation for improved multi-step reasoning in question answering tasks.

## Files and Folders Description

**Data Files:**

- `hotpot_train_5000samples_2025-06-11_18-31-48.jsonl` - Training subset of HotpotQA dataset with 5000 samples
- `hotpot_val_1000samples_2025-06-11_18-31-48.jsonl` - Validation subset of HotpotQA dataset with 1000 samples

**Datasets Folder:**


- `datasets/preference_datasets/` - Contains preference datasets for IPO training
- `datasets/hotpotqa_splitted_samples/` - Contains the HotpotQA dataset train and validation samples split into smaller files for easier processing and dataset downloading

**Notebooks:**

- `notebooks/preference_dataset_generation.ipynb` - Preference dataset creation and processing
- `notebooks/preference_dataset_generation_with_training.ipynb` - IPO injected preference dataset creation
- `notebooks/train_ipo_clean.ipynb` - Clean version of IPO training notebook
- `notebooks/evaluate_models.ipynb` - Model evaluation and performance analysis notebook



**Supporting Files:**

- `fewshot_examples/fewshot_examples.json` - Few-shot examples generated by using GPT-4o

## How to Run files

DISCLAIMERS: 
- There are TODO comments in the notebooks to update the paths to the files. Please make sure to update them before running the notebooks.
- The notebooks are designed to be run in Google Colab. Make sure to install the required dependencies in the first cell of each notebook.
- Preference dataset generation and training notebooks use huggingface and wandb modules. Make sure to have a HuggingFace account and a WandB account to run the notebooks and set environment tokens of 'HUGGINGFACE_TOKEN' and 'WANDB_API_KEY' in the colab environment (or your local environment).

### Preference Dataset Generation
preference_dataset_generation.ipynb

- Install the dependencies in the first cell of the notebook in the colab
- Set the fewshot examples file path in the notebook to the `fewshot_examples/fewshot_examples.json` file
- For different models for query generation, you can change the model name in the second cell of the notebook
- In the third cell, you can download the hotpotqa dataset from HuggingFace or use the one in the repository by uploading it to the colab.


Change the dataset path to get the splitted dataset from the repository by defining the directory of the dataset in the notebook

  ```python
  train_filename = "hotpot_train_5000samples_2025-06-11_18-31-48.jsonl"
  val_filename = "hotpot_val_1000samples_2025-06-11_18-31-48.jsonl"
  ```

- Run the finetuning cell if not wanted to use the default dataset.
- The notebook will create a preference dataset and it can be formatted at the end for a better dataset structure.

### Preference Dataset Generation with Training
preference_dataset_generation_with_training.ipynb

- This file is similar to the previous one but it includes the training of the IPO model in the process single hop function.

### Training IPO Model
train_ipo_clean.ipynb

- Install the dependencies in the first cell of the notebook in the colab
- This notebook creates a torch Dataset class using the preference dataset created in the previous step. Dataset Class uses the non formatted preference dataset created in the folder
  `new_datasets/preference_datasets/`
- The training is done using the T5-Flan model with the preference dataset.
- before training the model change the name of the saved folder for better convention

  ```python
  model_name = "epoch_x_{model_configuration}"
  ```


### Evaluating Models
evaluate_models.ipynb

- Install the dependencies in the first cell of the notebook in the colab
- This notebook evaluates the trained models using the HotpotQA dataset and the ColBERT embeddings
- The evaluation is done using the few-shot examples created in the previous step.
- The few-shot examples are loaded from the `fewshot_examples.json` file in the `datasets/` folder.
- The evaluation is done using the T5-Flan model with the preference dataset.
- The evaluation results are saved in the `evaluation_results/` folder.
- The evaluation is done in three steps:
  1. Evaluate the base model on the HotpotQA dataset
  2. Load the trained query generation model
  3. Evaluate the trained model on the HotpotQA dataset

  ## Authors

  - Oğuz Kağan Hitit
  - Eren Yavuz
